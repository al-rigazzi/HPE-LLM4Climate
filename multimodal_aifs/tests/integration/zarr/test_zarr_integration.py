#!/usr/bin/env python3
"""
Direct test of Zarr integration with AIFS multimodal system.
This script tests the complete pipeline: Zarr â†’ 5D tensor â†’ AIFS ready format.
"""

import sys
from pathlib import Path

import numpy as np
import pytest
import torch

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

print("ğŸ§ª Testing Zarr Integration with AIFS Multimodal System")
print("=" * 60)

try:
    import xarray as xr
    import zarr

    print(f"âœ… Dependencies loaded successfully")
    print(f"   ğŸ“¦ zarr version: {zarr.__version__}")
    print(f"   ğŸ“¦ xarray version: {xr.__version__}")
    print(f"   ğŸ“¦ torch version: {torch.__version__}")
except ImportError as e:
    print(f"âŒ Missing dependencies: {e}")
    sys.exit(1)


def test_zarr_to_aifs_pipeline():
    """Test the complete Zarr â†’ AIFS pipeline."""

    print("\nğŸ“ Step 1: Loading Zarr dataset")
    print("-" * 30)

    zarr_path = "test_climate.zarr"
    if not Path(zarr_path).exists():
        print(f"âŒ Test dataset not found: {zarr_path}")
        pytest.fail(f"Test dataset not found: {zarr_path}")

    try:
        # Load dataset
        ds = xr.open_zarr(zarr_path)
        print(f"âœ… Dataset loaded: {zarr_path}")
        print(f"   ğŸ“Š Dimensions: {dict(ds.sizes)}")
        print(f"   ğŸ”¢ Variables: {list(ds.data_vars.keys())}")

        # Get time range
        time_values = ds.time.values
        print(f"   ğŸ“… Time range: {str(time_values[0])[:19]} to {str(time_values[-1])[:19]}")

    except Exception as e:
        print(f"âŒ Failed to load dataset: {e}")
        pytest.fail(f"Failed to load dataset: {e}")

    print("\nğŸ”„ Step 2: Converting to AIFS tensor format")
    print("-" * 30)

    try:
        # Select a subset of data (first 4 timesteps)
        subset = ds.isel(time=slice(0, 4))
        print(f"âœ… Selected subset: {dict(subset.sizes)}")

        # Get variables
        variables = list(subset.data_vars.keys())
        print(f"   ğŸ”¢ Variables: {variables}")

        # Convert to numpy arrays and stack
        arrays = []
        for var in variables:
            var_data = subset[var].values  # Shape: [time, lat, lon]
            arrays.append(var_data)
            print(f"   ğŸ“Š {var}: {var_data.shape}")

        # Stack variables: [time, variables, lat, lon]
        stacked = np.stack(arrays, axis=1)
        print(f"âœ… Stacked shape: {stacked.shape}")

        # Convert to PyTorch tensor
        tensor = torch.from_numpy(stacked).float()

        # Add batch dimension: [batch=1, time, variables, lat, lon]
        tensor = tensor.unsqueeze(0)

        print(f"âœ… Final AIFS tensor shape: {tensor.shape}")
        print(
            f"   ğŸ“ Format: [batch={tensor.shape[0]}, time={tensor.shape[1]}, "
            f"vars={tensor.shape[2]}, height={tensor.shape[3]}, width={tensor.shape[4]}]"
        )

    except Exception as e:
        print(f"âŒ Failed tensor conversion: {e}")
        pytest.fail(f"Failed tensor conversion: {e}")

    print("\nğŸ§  Step 3: AIFS Integration Check")
    print("-" * 30)

    try:
        # Check tensor properties
        print(f"âœ… Tensor dtype: {tensor.dtype}")
        print(f"âœ… Tensor device: {tensor.device}")
        print(f"âœ… Memory usage: {tensor.numel() * tensor.element_size() / 1024:.2f} KB")

        # Check for NaN/Inf values
        has_nan = torch.isnan(tensor).any()
        has_inf = torch.isinf(tensor).any()
        print(f"âœ… Data quality: NaN={has_nan}, Inf={has_inf}")

        # Basic statistics
        print(f"âœ… Data range: [{tensor.min().item():.3f}, {tensor.max().item():.3f}]")
        print(f"âœ… Data mean: {tensor.mean().item():.3f}")
        print(f"âœ… Data std: {tensor.std().item():.3f}")

        # Simulate AIFS tokenizer input
        batch_size, time_steps, num_vars, height, width = tensor.shape
        print(f"\nğŸ¯ AIFS Multimodal Integration:")
        print(f"   âœ… Batch size: {batch_size} (ready for processing)")
        print(f"   âœ… Time steps: {time_steps} (temporal sequence)")
        print(f"   âœ… Variables: {num_vars} (climate features)")
        print(f"   âœ… Spatial: {height}x{width} (grid resolution)")
        print(f"   âœ… Total features: {num_vars * height * width} per timestep")

    except Exception as e:
        print(f"âŒ Integration check failed: {e}")
        pytest.fail(f"Integration check failed: {e}")

    print("\nğŸ‰ Success! Zarr â†’ AIFS Pipeline Complete")
    print("=" * 60)
    print("The zarr dataset can be successfully loaded and converted")
    print("to the 5D tensor format [B,T,V,H,W] expected by AIFS models.")
    print("\nNext steps:")
    print("â€¢ Use ZarrClimateLoader class for production workflows")
    print("â€¢ Integrate with AIFS TimeSeries tokenizer")
    print("â€¢ Feed tokenized data to Llama 3-8B model")
    print("â€¢ Apply cross-attention fusion for multimodal processing")
    # Test passes by reaching this point without failures


if __name__ == "__main__":
    success = test_zarr_to_aifs_pipeline()
    sys.exit(0 if success else 1)
